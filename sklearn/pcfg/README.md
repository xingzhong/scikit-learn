### Recursive Bayesian estimation based on stochastic context-free grammar 

A grammar is a generative model contains a set of productions that can be used to generate data samples.
By associating probability into each productions in a grammar, 
a stochastic context-free grammar (SCFG) can be constructed for probablistic data modelling. 

A **SCFG** can be determined through start symbol, a set of production rules and the probability associated with them.
When applying the grammar to derive data sample, one can applied each productions iteratively from the start symbol.
Such derivation can be arranged in a tree sturcture called a parse tree which represents the syntactic structure of a sequence produced by a grammar.

**SCFG** extend context-free grammars similar to how hidden Markov models (HMM) extend regular grammars. 
Intuitively, the same **HMM** application can be extends through **SCFG** model by supporting more model flexibility. 

In a typical state space model, underlying observable time series are sequentially generated by internal hidden states follow Gaussian distribution.
By incrementally accept observations through time, the hidden states can be estimated in Bayesian fashion.

- If the state transition is linear and Gaussian (Gaussian-Markov property), such states can be estimated by Kalman filter. 
- If the state transition is non-linear, but still have Markov property, such states can be estimated by Partical filter.
 

====
This implementation is for research purpose only.
